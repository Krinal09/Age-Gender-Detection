{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "netjOmwTLjrA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation\n",
        "from os import listdir\n",
        "from numpy import asarray,save\n",
        "from keras.utils import load_img, img_to_array\n",
        "import random\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvjtHLRQC3ob",
        "outputId": "317da59c-9eee-4801-86c2-a369ab34abe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYR1XXMf5a7L"
      },
      "outputs": [],
      "source": [
        "train = ImageDataGenerator(rescale =1.0/255.0, rotation_range=25, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,vertical_flip=True,\n",
        "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
        "test = ImageDataGenerator(rescale=1.0/255.0, rotation_range=25, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,vertical_flip=True,\n",
        "                         horizontal_flip=True, fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhkwUMZKABXO"
      },
      "outputs": [],
      "source": [
        "# initial parameters\n",
        "epochs = 100\n",
        "lr = 1e-3\n",
        "batch_size = 64\n",
        "img_dims = (96,96,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQCjSPiEAMSI",
        "outputId": "4eaf9654-9dc3-4517-e7c9-c11f2526a470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5645 images belonging to 2 classes.\n",
            "Found 346 images belonging to 2 classes.\n",
            "train_index : {'man': 0, 'woman': 1}\n",
            "test_index: {'man': 0, 'woman': 1}\n"
          ]
        }
      ],
      "source": [
        "train_data = train.flow_from_directory('/content/drive/MyDrive/Gender and Age Detection Final Project Data/Gender Dataset Main Final Project/train', target_size=(96,96), class_mode='categorical')\n",
        "test_data = test.flow_from_directory('/content/drive/MyDrive/Gender and Age Detection Final Project Data/Gender Dataset Main Final Project/test', target_size=(96,96), class_mode='categorical')\n",
        "print('train_index :', train_data.class_indices)\n",
        "print('test_index:', test_data.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY06pkEZD9Ae"
      },
      "outputs": [],
      "source": [
        "model= Sequential()\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\": #Returns a string, either 'channels_first' or 'channels_last'\n",
        "    chanDim = 1\n",
        "#CNN1\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu',input_shape=(96,96,3), padding='same'))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3,3), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "#CNN2\n",
        "model.add(Conv2D(64,(3,3),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "#CNN3\n",
        "model.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "model.add(Dropout(0.25))  \n",
        "#CNN4\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding=\"same\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "batch_size=128\n",
        "epochs =100\n",
        "classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrhGLn3JH0aq",
        "outputId": "30f42940-e906-4055-fb3a-6c2a9290a233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 96, 96, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 96, 96, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              8389632   \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,638,018\n",
            "Trainable params: 8,635,266\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(classes))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ddrbc_VJlzy",
        "outputId": "cee94a53-0e21-443b-eb62-135ca00dde09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 96, 96, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 96, 96, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              8389632   \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 2)                 2050      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,638,018\n",
            "Trainable params: 8,635,266\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=lr, decay=lr/epochs)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82zdiqRcLWWW",
        "outputId": "2fe25747-6edb-4e51-b1b6-048eb76ba90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "177/177 [==============================] - 1400s 8s/step - loss: 0.7609 - accuracy: 0.6677 - val_loss: 1.2326 - val_accuracy: 0.5087\n",
            "Epoch 2/100\n",
            "177/177 [==============================] - 30s 172ms/step - loss: 0.5995 - accuracy: 0.7268 - val_loss: 2.0239 - val_accuracy: 0.5260\n",
            "Epoch 3/100\n",
            "177/177 [==============================] - 31s 175ms/step - loss: 0.5723 - accuracy: 0.7364 - val_loss: 1.1571 - val_accuracy: 0.6301\n",
            "Epoch 4/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.5243 - accuracy: 0.7605 - val_loss: 0.4024 - val_accuracy: 0.7803\n",
            "Epoch 5/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.4940 - accuracy: 0.7708 - val_loss: 1.0654 - val_accuracy: 0.5202\n",
            "Epoch 6/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.4795 - accuracy: 0.7860 - val_loss: 0.5571 - val_accuracy: 0.7197\n",
            "Epoch 7/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.4433 - accuracy: 0.8005 - val_loss: 0.5584 - val_accuracy: 0.7312\n",
            "Epoch 8/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.4404 - accuracy: 0.8053 - val_loss: 0.6551 - val_accuracy: 0.6676\n",
            "Epoch 9/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.4100 - accuracy: 0.8168 - val_loss: 0.4477 - val_accuracy: 0.8121\n",
            "Epoch 10/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.4126 - accuracy: 0.8163 - val_loss: 0.2919 - val_accuracy: 0.8642\n",
            "Epoch 11/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.3854 - accuracy: 0.8308 - val_loss: 1.1553 - val_accuracy: 0.5607\n",
            "Epoch 12/100\n",
            "177/177 [==============================] - 31s 175ms/step - loss: 0.3704 - accuracy: 0.8372 - val_loss: 1.5557 - val_accuracy: 0.5694\n",
            "Epoch 13/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.3505 - accuracy: 0.8523 - val_loss: 0.2831 - val_accuracy: 0.9104\n",
            "Epoch 14/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.3762 - accuracy: 0.8354 - val_loss: 0.8178 - val_accuracy: 0.6243\n",
            "Epoch 15/100\n",
            "177/177 [==============================] - 31s 176ms/step - loss: 0.3455 - accuracy: 0.8482 - val_loss: 0.3202 - val_accuracy: 0.8699\n",
            "Epoch 16/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.3305 - accuracy: 0.8588 - val_loss: 0.6058 - val_accuracy: 0.7543\n",
            "Epoch 17/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.3304 - accuracy: 0.8606 - val_loss: 0.3473 - val_accuracy: 0.8439\n",
            "Epoch 18/100\n",
            "177/177 [==============================] - 31s 175ms/step - loss: 0.3197 - accuracy: 0.8593 - val_loss: 0.3267 - val_accuracy: 0.8353\n",
            "Epoch 19/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.3090 - accuracy: 0.8702 - val_loss: 0.4333 - val_accuracy: 0.8064\n",
            "Epoch 20/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.3030 - accuracy: 0.8749 - val_loss: 1.1892 - val_accuracy: 0.6301\n",
            "Epoch 21/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.2967 - accuracy: 0.8721 - val_loss: 0.2079 - val_accuracy: 0.9162\n",
            "Epoch 22/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2972 - accuracy: 0.8721 - val_loss: 0.4302 - val_accuracy: 0.8584\n",
            "Epoch 23/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2891 - accuracy: 0.8801 - val_loss: 0.1816 - val_accuracy: 0.9249\n",
            "Epoch 24/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.2796 - accuracy: 0.8831 - val_loss: 0.2301 - val_accuracy: 0.9075\n",
            "Epoch 25/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.2631 - accuracy: 0.8941 - val_loss: 0.1863 - val_accuracy: 0.9046\n",
            "Epoch 26/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2512 - accuracy: 0.9001 - val_loss: 0.3061 - val_accuracy: 0.8497\n",
            "Epoch 27/100\n",
            "177/177 [==============================] - 33s 186ms/step - loss: 0.3081 - accuracy: 0.8657 - val_loss: 0.5807 - val_accuracy: 0.7803\n",
            "Epoch 28/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2883 - accuracy: 0.8810 - val_loss: 0.2133 - val_accuracy: 0.8988\n",
            "Epoch 29/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2671 - accuracy: 0.8859 - val_loss: 0.3387 - val_accuracy: 0.8382\n",
            "Epoch 30/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.2352 - accuracy: 0.9022 - val_loss: 0.2445 - val_accuracy: 0.9017\n",
            "Epoch 31/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2592 - accuracy: 0.8960 - val_loss: 0.5620 - val_accuracy: 0.7543\n",
            "Epoch 32/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.2536 - accuracy: 0.8921 - val_loss: 0.1666 - val_accuracy: 0.9335\n",
            "Epoch 33/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.2431 - accuracy: 0.8957 - val_loss: 0.1631 - val_accuracy: 0.9191\n",
            "Epoch 34/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2423 - accuracy: 0.9012 - val_loss: 0.1487 - val_accuracy: 0.9364\n",
            "Epoch 35/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.2350 - accuracy: 0.9104 - val_loss: 0.1447 - val_accuracy: 0.9422\n",
            "Epoch 36/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2583 - accuracy: 0.8962 - val_loss: 0.1966 - val_accuracy: 0.9191\n",
            "Epoch 37/100\n",
            "177/177 [==============================] - 30s 167ms/step - loss: 0.2261 - accuracy: 0.9132 - val_loss: 0.3623 - val_accuracy: 0.8497\n",
            "Epoch 38/100\n",
            "177/177 [==============================] - 33s 185ms/step - loss: 0.2216 - accuracy: 0.9128 - val_loss: 0.1521 - val_accuracy: 0.9480\n",
            "Epoch 39/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2137 - accuracy: 0.9109 - val_loss: 0.3783 - val_accuracy: 0.8584\n",
            "Epoch 40/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2264 - accuracy: 0.9065 - val_loss: 0.6143 - val_accuracy: 0.7977\n",
            "Epoch 41/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.2317 - accuracy: 0.9056 - val_loss: 0.2890 - val_accuracy: 0.8931\n",
            "Epoch 42/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2415 - accuracy: 0.9042 - val_loss: 0.3541 - val_accuracy: 0.8439\n",
            "Epoch 43/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2475 - accuracy: 0.9013 - val_loss: 0.4029 - val_accuracy: 0.8353\n",
            "Epoch 44/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.2284 - accuracy: 0.9038 - val_loss: 0.1210 - val_accuracy: 0.9538\n",
            "Epoch 45/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2178 - accuracy: 0.9132 - val_loss: 0.1124 - val_accuracy: 0.9509\n",
            "Epoch 46/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2215 - accuracy: 0.9104 - val_loss: 0.2290 - val_accuracy: 0.8988\n",
            "Epoch 47/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.2302 - accuracy: 0.9102 - val_loss: 0.1140 - val_accuracy: 0.9538\n",
            "Epoch 48/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.1987 - accuracy: 0.9233 - val_loss: 0.1887 - val_accuracy: 0.9249\n",
            "Epoch 49/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.2129 - accuracy: 0.9151 - val_loss: 0.3299 - val_accuracy: 0.8757\n",
            "Epoch 50/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.2052 - accuracy: 0.9199 - val_loss: 0.1032 - val_accuracy: 0.9509\n",
            "Epoch 51/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.2042 - accuracy: 0.9198 - val_loss: 0.1471 - val_accuracy: 0.9393\n",
            "Epoch 52/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.2003 - accuracy: 0.9194 - val_loss: 0.1464 - val_accuracy: 0.9451\n",
            "Epoch 53/100\n",
            "177/177 [==============================] - 30s 171ms/step - loss: 0.2061 - accuracy: 0.9190 - val_loss: 0.3433 - val_accuracy: 0.8613\n",
            "Epoch 54/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1943 - accuracy: 0.9247 - val_loss: 0.1102 - val_accuracy: 0.9509\n",
            "Epoch 55/100\n",
            "177/177 [==============================] - 33s 188ms/step - loss: 0.1988 - accuracy: 0.9189 - val_loss: 0.2068 - val_accuracy: 0.9075\n",
            "Epoch 56/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2038 - accuracy: 0.9213 - val_loss: 0.4115 - val_accuracy: 0.8699\n",
            "Epoch 57/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2144 - accuracy: 0.9139 - val_loss: 0.1810 - val_accuracy: 0.9249\n",
            "Epoch 58/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.2041 - accuracy: 0.9187 - val_loss: 0.0732 - val_accuracy: 0.9769\n",
            "Epoch 59/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.1958 - accuracy: 0.9252 - val_loss: 0.0967 - val_accuracy: 0.9566\n",
            "Epoch 60/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1932 - accuracy: 0.9221 - val_loss: 0.0836 - val_accuracy: 0.9711\n",
            "Epoch 61/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.1810 - accuracy: 0.9313 - val_loss: 0.1104 - val_accuracy: 0.9595\n",
            "Epoch 62/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1884 - accuracy: 0.9283 - val_loss: 0.3557 - val_accuracy: 0.8671\n",
            "Epoch 63/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1997 - accuracy: 0.9236 - val_loss: 0.1010 - val_accuracy: 0.9538\n",
            "Epoch 64/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.1926 - accuracy: 0.9217 - val_loss: 0.1497 - val_accuracy: 0.9422\n",
            "Epoch 65/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1898 - accuracy: 0.9260 - val_loss: 0.1192 - val_accuracy: 0.9509\n",
            "Epoch 66/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.2017 - accuracy: 0.9160 - val_loss: 0.2107 - val_accuracy: 0.8960\n",
            "Epoch 67/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.1936 - accuracy: 0.9260 - val_loss: 0.1678 - val_accuracy: 0.9422\n",
            "Epoch 68/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1898 - accuracy: 0.9244 - val_loss: 0.1016 - val_accuracy: 0.9538\n",
            "Epoch 69/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1860 - accuracy: 0.9286 - val_loss: 0.5188 - val_accuracy: 0.8006\n",
            "Epoch 70/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.1946 - accuracy: 0.9222 - val_loss: 0.2541 - val_accuracy: 0.8728\n",
            "Epoch 71/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1890 - accuracy: 0.9261 - val_loss: 0.1106 - val_accuracy: 0.9566\n",
            "Epoch 72/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1879 - accuracy: 0.9298 - val_loss: 0.3152 - val_accuracy: 0.8757\n",
            "Epoch 73/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.1969 - accuracy: 0.9201 - val_loss: 0.1192 - val_accuracy: 0.9509\n",
            "Epoch 74/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.1763 - accuracy: 0.9327 - val_loss: 0.1806 - val_accuracy: 0.9306\n",
            "Epoch 75/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.1817 - accuracy: 0.9295 - val_loss: 0.1083 - val_accuracy: 0.9480\n",
            "Epoch 76/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.1816 - accuracy: 0.9327 - val_loss: 0.1072 - val_accuracy: 0.9566\n",
            "Epoch 77/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1834 - accuracy: 0.9249 - val_loss: 0.0720 - val_accuracy: 0.9653\n",
            "Epoch 78/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1718 - accuracy: 0.9353 - val_loss: 0.0820 - val_accuracy: 0.9538\n",
            "Epoch 79/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.1714 - accuracy: 0.9362 - val_loss: 0.0839 - val_accuracy: 0.9624\n",
            "Epoch 80/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1861 - accuracy: 0.9288 - val_loss: 0.1462 - val_accuracy: 0.9422\n",
            "Epoch 81/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1749 - accuracy: 0.9304 - val_loss: 0.3888 - val_accuracy: 0.8526\n",
            "Epoch 82/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.1813 - accuracy: 0.9290 - val_loss: 0.0836 - val_accuracy: 0.9595\n",
            "Epoch 83/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1842 - accuracy: 0.9247 - val_loss: 0.1099 - val_accuracy: 0.9566\n",
            "Epoch 84/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1905 - accuracy: 0.9261 - val_loss: 0.3164 - val_accuracy: 0.8497\n",
            "Epoch 85/100\n",
            "177/177 [==============================] - 31s 175ms/step - loss: 0.1901 - accuracy: 0.9256 - val_loss: 0.1458 - val_accuracy: 0.9393\n",
            "Epoch 86/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1835 - accuracy: 0.9309 - val_loss: 0.0931 - val_accuracy: 0.9595\n",
            "Epoch 87/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1806 - accuracy: 0.9265 - val_loss: 0.0968 - val_accuracy: 0.9624\n",
            "Epoch 88/100\n",
            "177/177 [==============================] - 31s 174ms/step - loss: 0.1658 - accuracy: 0.9350 - val_loss: 0.0830 - val_accuracy: 0.9682\n",
            "Epoch 89/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1677 - accuracy: 0.9364 - val_loss: 0.0989 - val_accuracy: 0.9653\n",
            "Epoch 90/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1781 - accuracy: 0.9300 - val_loss: 0.0746 - val_accuracy: 0.9682\n",
            "Epoch 91/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.1646 - accuracy: 0.9360 - val_loss: 0.0633 - val_accuracy: 0.9798\n",
            "Epoch 92/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1721 - accuracy: 0.9391 - val_loss: 0.5121 - val_accuracy: 0.8324\n",
            "Epoch 93/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1595 - accuracy: 0.9375 - val_loss: 0.1665 - val_accuracy: 0.9277\n",
            "Epoch 94/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.1730 - accuracy: 0.9332 - val_loss: 0.0820 - val_accuracy: 0.9682\n",
            "Epoch 95/100\n",
            "177/177 [==============================] - 30s 170ms/step - loss: 0.1809 - accuracy: 0.9345 - val_loss: 0.4992 - val_accuracy: 0.8382\n",
            "Epoch 96/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1599 - accuracy: 0.9412 - val_loss: 0.0665 - val_accuracy: 0.9769\n",
            "Epoch 97/100\n",
            "177/177 [==============================] - 31s 172ms/step - loss: 0.1635 - accuracy: 0.9391 - val_loss: 0.1349 - val_accuracy: 0.9422\n",
            "Epoch 98/100\n",
            "177/177 [==============================] - 30s 169ms/step - loss: 0.1587 - accuracy: 0.9399 - val_loss: 0.1210 - val_accuracy: 0.9538\n",
            "Epoch 99/100\n",
            "177/177 [==============================] - 30s 168ms/step - loss: 0.1632 - accuracy: 0.9384 - val_loss: 0.1091 - val_accuracy: 0.9509\n",
            "Epoch 100/100\n",
            "177/177 [==============================] - 31s 173ms/step - loss: 0.1623 - accuracy: 0.9398 - val_loss: 0.1178 - val_accuracy: 0.9364\n",
            "loss 0.14075706899166107\n",
            "accuracy 0.9482728242874146\n"
          ]
        }
      ],
      "source": [
        "his=model.fit(train_data,epochs=epochs,batch_size=128,verbose=1,validation_data=test_data)\n",
        "value=model.evaluate(train_data,verbose=0)\n",
        "print('loss', value[0])\n",
        "print('accuracy', value[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVLV8vmVd4Uw"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Model Save/Gender_Detection.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMg29ZoCUZ7I91mYz0nLgUu",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1DPKgNHgz1jPVmOoTfrZ6fbpSMCzQd__d",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
